#!/usr/bin/env python

# pylint: disable=line-too-long,missing-docstring,invalid-name,wrong-import-position,multiple-imports

'''
Launcher for the reactor system.
'''

# allow importing directly from src/
import sys
sys.path.append('src')

import os

from pensive import DEFAULT_PORT as PENSIVE_DEFAULT_PORT
from log import DEFAULT_RECORD_PORT as LOG_DEFAULT_RECORD_PORT, DEFAULT_WEB_PORT as LOG_DEFAULT_WEB_PORT

# parse command-line arguments
from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter, REMAINDER

parser = ArgumentParser(description='Reactor system launcher', formatter_class=ArgumentDefaultsHelpFormatter)
parser.add_argument('-v', '--verbose', metavar='MODULE', action='append', help='verbose logging for specified modules')
parser.add_argument('-d', '--debug', metavar='MODULE', action='append', help='debug logging for specified modules')
parser.add_argument('-lf', '--log-file', metavar='LOG_FILE', help='override log file')
parser.add_argument('-lh', '--log-host', metavar='LOG_HOST', help='log server hostname', default='localhost')
parser.add_argument('-lp', '--log-port', metavar='LOG_PORT', type=int, help='log server port', default=LOG_DEFAULT_RECORD_PORT)

subparsers = parser.add_subparsers(title='subcommands', dest='command')

db_parser = subparsers.add_parser('db', help='database control', description='control the system database', formatter_class=ArgumentDefaultsHelpFormatter)
db_parser.add_argument('-p', '--port', metavar='PORT', type=int, default=PENSIVE_DEFAULT_PORT, help='server port')
db_parser.add_argument('-d', '--detach', action='store_true', help='detach as daemon')

log_parser = subparsers.add_parser('log', help='log control', description='control the log server', formatter_class=ArgumentDefaultsHelpFormatter)
log_parser.add_argument('-u', '--db-url', metavar='DB_URL', default='sqlite:///db/log.sqlite', help='server database URL')
log_parser.add_argument('-rp', '--record-port', metavar='RECORD_PORT', type=int, default=LOG_DEFAULT_RECORD_PORT, help='server record port')
log_parser.add_argument('-wp', '--web-port', metavar='WEB_PORT', type=int, default=LOG_DEFAULT_WEB_PORT, help='server web port')
log_parser.add_argument('-d', '--detach', action='store_true', help='detach as daemon')

test_parser = subparsers.add_parser('test', help='unit test launcher', description='discover and launch unit tests with logging', formatter_class=ArgumentDefaultsHelpFormatter)
test_parser.add_argument('-c', '--continue', dest='cont', action='store_true', help='continue despite failures')
test_parser.add_argument('-q', '--quiet', action='store_true', help='decrease verbosity')
test_parser.add_argument('-v', '--verbose', action='store_true', help='increase verbosity')
test_parser.add_argument('path', nargs=REMAINDER, metavar='PATH', help='search path for tests')

shell_parser = subparsers.add_parser('shell', help='Python shell', description='launch Python', formatter_class=ArgumentDefaultsHelpFormatter, add_help=False)
shell_parser.add_argument('-h', '--help', action='store_true', help='show this help message and exit')
shell_parser.add_argument('-m', '--module', dest='ignored', action='store_true', help='deprecated')
shell_parser.add_argument('module', nargs='?', help='module or file to run')
shell_parser.add_argument('args', nargs=REMAINDER, help='execution arguments')

load_parser = subparsers.add_parser('load', help='load database', description='load database', formatter_class=ArgumentDefaultsHelpFormatter)
load_parser.add_argument('-a', '--address', metavar='HOST', help='database server host')
load_parser.add_argument('-s', '--store', metavar='STORE', help='database store')
load_parser.add_argument('-p', '--path', metavar='DB_PATH', help='path for the load', default='/')
load_parser.add_argument('json_path', metavar='JSON_PATH', help='JSON file to load')

dump_parser = subparsers.add_parser('dump', help='dump database', description='dump database', formatter_class=ArgumentDefaultsHelpFormatter)
dump_parser.add_argument('-a', '--address', metavar='HOST', help='database server host')
dump_parser.add_argument('-s', '--store', metavar='STORE', help='database store')
dump_parser.add_argument('path', nargs='?', metavar='PATH', help='path for the dump', default='/')
group = dump_parser.add_mutually_exclusive_group()
group.add_argument('-c', '--compress', action='store_true', help='compress JSON', default=False)
group.add_argument('-p', '--pretty', action='store_true', help='print JSON nicely', default=False)

superdump_parser = subparsers.add_parser('superdump', help='dump database', description='dump database', formatter_class=ArgumentDefaultsHelpFormatter)
superdump_parser.add_argument('-a', '--address', metavar='HOST', help='database server host')
superdump_parser.add_argument('folder', metavar='FOLDER', help='folder to save the stores')

print_parser = subparsers.add_parser('print', help='print database', description='print database', formatter_class=ArgumentDefaultsHelpFormatter)
print_parser.add_argument('-a', '--address', metavar='HOST', help='database server host')
print_parser.add_argument('-s', '--store', metavar='STORE', help='database store')
print_parser.add_argument('-p', '--path', metavar='PATH', help='path to a JSON database')
print_parser.add_argument('url', nargs='+', metavar='URL', help='url to print')

#args, other_args = parser.parse_known_args()
args = parser.parse_args()

# configure the root logger to accept all records
import logging
logger = logging.getLogger()
logger.setLevel(logging.NOTSET)

formatter = logging.Formatter('%(asctime)s.%(msecs)03d [%(name)s] %(filename)s:%(lineno)d\t%(levelname)s:\t%(message)s')

# set up colored logging to console
from rainbow_logging_handler import RainbowLoggingHandler
console_handler = RainbowLoggingHandler(sys.stderr)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# set up logging to file for all records
log_path = args.log_file
if not log_path:
    import datetime
    name = '{}-{:%Y%m%d-%H%M%S}.log'.format(
        os.path.basename(__file__), datetime.datetime.now())
    log_path = os.path.join('log', name)

    # create the log directory if needed
    if not os.path.exists('log'):
        os.mkdir('log')

handler = logging.FileHandler(log_path)
handler.setFormatter(formatter)
logger.addHandler(handler)

# set up logging to server for all records
from log.handler import LogServerHandler
handler = LogServerHandler(args.log_host, args.log_port)
logger.addHandler(handler)

# install level filter for console output only
from util.log import LevelFilter
lf = LevelFilter()
console_handler.addFilter(lf)

# default console output to WARN level
lf.add('', logging.WARN)

# attempt to register numpy database codecs
from pensive.coders import register_numpy
if not register_numpy():
    logger.warn('failed to load numpy database coders')

# process logging verbosity flags
verbose = args.verbose or []
try:
    verbose += os.environ['REACTOR_VERBOSE'].split(';')
except KeyError:
    pass

if verbose:
    os.environ['REACTOR_VERBOSE'] = ';'.join(verbose)
    for m in verbose:
        lf.add(m, logging.INFO)

debug = args.debug or []
try:
    debug += os.environ['REACTOR_DEBUG'].split(';')
except KeyError:
    pass

if debug:
    os.environ['REACTOR_DEBUG'] = ';'.join(debug)
    for m in debug:
        lf.add(m, logging.DEBUG)

# launch the target command
if args.command == 'db':
    from pensive.server import PensiveServer
    PensiveServer(args.port).run()

elif args.command == 'log':
    from log.server import LogServer
    LogServer(args.db_url, record_port=args.record_port, web_port=args.web_port).run()

elif args.command == 'test':
    # record all message during testing
    lf.add('', logging.DEBUG)

    subargs = ['--cov=src', '--cov-report=html', '--cov-report=term']

    if not args.cont:
        subargs.append('--maxfail=1')
    if args.quiet:
        subargs.append('-q')
    if args.verbose:
        subargs.append('-v')

    # show extra details for skipped and failed tests
    subargs.append('-rsx')

    subargs.extend([os.path.join('test', p) for p in args.path] or ['test'])

    import pytest
    result = pytest.main(subargs)

    # return the pytest error code for CI build status use
    raise SystemExit(result)

elif args.command == 'shell':
    if args.module:
        import runpy

        sys.argv = [args.module] + args.args

        if os.sep in args.module or args.module.endswith('.py'):
            # run the file directly
            runpy.run_path(args.module, run_name='__main__')
        else:
            # run the module directly
            runpy.run_module(args.module, run_name='__main__', alter_sys=True)

    elif args.help:
        shell_parser.print_help()
    else:
        try:
            # try using IPython shell if installed
            import IPython
        except ImportError:
            # fall back to regular Python shell
            import code
            code.interact()
        else:
            IPython.start_ipython(argv=args.args)

elif args.command == 'load':
    # handle compressed JSON files
    if args.json_path.endswith('.gz'):
        import gzip
        data = gzip.open(args.json_path, 'rb').read()
    else:
        data = open(args.json_path).read()

    # load the JSON object
    import json
    obj = json.loads(data)

    # connect to the database
    from pensive.client import PensiveClient
    client = PensiveClient(args.address)

    # create or get the store
    if args.store and args.store not in client.index():
        store = client.create(args.store)
    else:
        store = client.store(args.store)

    # load the object
    store.put(args.path, obj)

elif args.command == 'dump':
    # connect to the database
    from pensive.client import PensiveClient
    client = PensiveClient(args.address)

    # get the store
    store = client.store(args.store)

    # load the object
    obj = store.get(args.path)

    # dump as JSON to stdout using json_encode for custom data types
    from pensive.client import json_encode
    if args.compress:
        from gzip import GzipFile
        GzipFile('', fileobj=sys.stdout).write(json_encode(obj))
    elif args.pretty:
        from pprint import pprint
        pprint(obj)
    else:
        print(json_encode(obj, indent=4))

elif args.command == 'superdump':
    # connect to the database
    from pensive.client import PensiveClient
    client = PensiveClient(args.address)

    from pensive.client import json_encode
    from gzip import GzipFile

    os.makedirs(args.folder)

    names = client.index()
    for (i, name) in enumerate(names):
        path = os.path.join(args.folder, '{}.json.gz'.format(name))
        print '{:3d} of {:3d}: {}'.format(i + 1, len(names), path)

        # get the store
        store = client.store(name)

        # load the object
        obj = store.get()

        # dump as JSON
        GzipFile('', fileobj=open(path, 'wb')).write(json_encode(obj))

elif args.command == 'print':
    if args.path:
        # read the file
        if args.path.endswith('.gz'):
            import gzip
            data = gzip.open(args.path, 'rb').read()
        else:
            data = open(args.path).read()

        # load the JSON object
        from pensive.client import json_decode
        obj = json_decode(data)

        # populate in-memory store
        from pensive.core import Store
        store = Store(obj)

    else:
        # connect to the database
        from pensive.client import PensiveClient
        client = PensiveClient(args.address)

        # get the store
        store = client.store(args.store)

    from pprint import pprint
    for url in args.url:
        print url, '-> '
        obj = store.get(url)

        if isinstance(obj, list):
            for (i, value) in enumerate(obj):
                print i, '-> '
                pprint(value)
        else:
            pprint(obj)
