{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.transform\n",
    "import sklearn.cross_validation\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import scipy.io\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "import random\n",
    "import scipy.misc\n",
    "import matplotlib\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model definition for VGG-16, 16-layer model from the paper:\n",
    "# \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"\n",
    "# Original source: https://gist.github.com/ksimonyan/211839e770f7b538e2d8\n",
    "\n",
    "# More pretrained models are available from\n",
    "# https://github.com/Lasagne/Recipes/blob/master/modelzoo/\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1)\n",
    "    net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1)\n",
    "    net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1)\n",
    "    net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1)\n",
    "    net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1)\n",
    "    net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1)\n",
    "    net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1)\n",
    "    net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1)\n",
    "    net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc7'] = DenseLayer(net['fc6'], num_units=4096)\n",
    "    net['fc8'] = DenseLayer(net['fc7'], num_units=40, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load model weights and metadata\n",
    "d = pickle.load(open('vgg16.pkl'))\n",
    "#d = pickle.load(open('vgg_finetuned_ARC2017_rotation_2_augmented_randombackground.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the network and fill with pretrained weights\n",
    "net = build_model()\n",
    "lasagne.layers.set_all_param_values(net['prob'], d['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The network expects input in a particular format and size.\n",
    "# We define a preprocessing function to load a file and apply the necessary transformations\n",
    "IMAGE_MEAN = d['mean value'][:, np.newaxis, np.newaxis]\n",
    "\n",
    "def prep_image(fn, ext='jpg',precrop=[0,-1,0,-1]): #precrop is if you want to crop the image before processing\n",
    "    \n",
    "    if ext=='npy':\n",
    "        im=np.load(fn)\n",
    "    else:\n",
    "        im = plt.imread(fn, ext)\n",
    "    \n",
    "    im=im[precrop[0]:precrop[1],precrop[2]:precrop[3]]\n",
    "    \n",
    "    # Resize so smallest dim = 256, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # discard alpha channel if present\n",
    "    im = im[:3]\n",
    "\n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - IMAGE_MEAN\n",
    "    return rawim, floatX(im[np.newaxis])\n",
    "\n",
    "def prep_image_rot_stage(stack,offset=70): #process np file for images taken from rotation stage\n",
    "    #load a stack of np files with multiple rotational images of the same object from the same view\n",
    "    #stack is _ by dim1 by dim2 by 3\n",
    "    #take a variance projection, threshold, and find the smallest bounding box\n",
    "    #return truncated stack, resized to _x3x224x224, the same processing as done in prep_image\n",
    "    #offset changes the vertical offset of the bounding box\n",
    "    \n",
    "    varproj=np.var(stack,0)[:,:,0] #only need to look at one channel\n",
    "    mask=varproj>np.mean(varproj)*.99 #where is there motion?\n",
    "    \n",
    "    #find bounding box\n",
    "    #because there are outliers due to camera defects, I find the median of the thresholded points\n",
    "    #and take the bounding box as 2x the stdev\n",
    "    c=np.nonzero(mask)\n",
    "    c1=np.int32(np.median(c[1]))\n",
    "    c0=np.int32(np.median(c[0]))-offset\n",
    "    sig1=np.int32(np.std(c[1])*2)\n",
    "    sig0=np.int32(np.std(c[0])*2)\n",
    "    sig=np.max([sig1,sig0]) #take the larger sig, construct square\n",
    "    \n",
    "    #bounding box extremes\n",
    "    low0=c0-sig\n",
    "    high0=c0+sig\n",
    "    low1=c1-sig\n",
    "    high1=c1+sig\n",
    "    if low0<0: #if offset goes negative, readjust\n",
    "        high0-=low0\n",
    "        low0=0\n",
    "    \n",
    "    stack_new=[skimage.transform.resize(im,(224,224)) for im in stack[:,low0:high0,low1:high1]]\n",
    "    stack_new=np.stack(stack_new,0)\n",
    "    #stack_raw=np.copy(stack_new)\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    stack_new=np.swapaxes(np.swapaxes(stack_new, 2, 3), 1, 2)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    stack_new=stack_new[:,::-1, :, :]# - np.expand_dims(IMAGE_MEAN,0)\n",
    "    \n",
    "    return stack_new#,stack_raw\n",
    "\n",
    "def prep_image_rot_stage_black_bkg():\n",
    "    pass\n",
    "\n",
    "def deprocess(im,RGB=True):\n",
    "    #by default, input im is BGR\n",
    "    \n",
    "    if RGB:\n",
    "        im = im[::-1, :, :]\n",
    "    im = np.swapaxes(np.swapaxes(im, 0, 1), 1, 2)\n",
    "        \n",
    "    #im = (im - im.min())\n",
    "    #im = im / im.max()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for loading the first ARC rotation dataset\n",
    "X = []\n",
    "y = []\n",
    "camera_view = [] #0 or 1, which camera view?\n",
    "directory='/home/kevin/Documents/ARC/ARC2017_rotation1/'\n",
    "for subdir in os.walk(directory): #first get the folders, which contain different classes of images\n",
    "    \n",
    "    dir_=subdir[0]\n",
    "    #get the class label\n",
    "    cls=dir_.partition('rotation1/')[-1]\n",
    "    if not cls or 'point_cloud' in cls: #if it's empty (the root directory); point cloud is handled below\n",
    "        continue\n",
    "    camera_pc=list() #to store the image numbers from camera0\n",
    "    #point cloud files' numbers need to be extracted because they correspond to one camera\n",
    "    for pc in os.listdir(dir_+'/point_cloud'):\n",
    "        if 'pc_' in pc:\n",
    "            camera_pc.append(int(pc.partition('.npy')[0][3:])) #get the numbers\n",
    "    #now loop over image files\n",
    "    (_, _, filenames) = os.walk(dir_).next() #in order to ignore the point clouds\n",
    "    X1=[]\n",
    "    X2=[]\n",
    "    y1=[]\n",
    "    y2=[]\n",
    "    for imfile in filenames:\n",
    "        imno=int(imfile.partition('.npy')[0][6:]) #image_().npy; to check against list to see which camera view it is\n",
    "        \n",
    "        #two different camera views handled separately\n",
    "        if imno in camera_pc:\n",
    "            X1.append(np.load(dir_+'/'+imfile))\n",
    "            y1.append(cls)\n",
    "        else:\n",
    "            X2.append(np.load(dir_+'/'+imfile))\n",
    "            y2.append(cls)\n",
    "    if not X1 or not X2:\n",
    "        print 'empty directory: '+dir_\n",
    "        continue\n",
    "    X1=prep_image_rot_stage(np.stack(X1,0))\n",
    "    X2=prep_image_rot_stage(np.stack(X2,0))\n",
    "    X.append(X1)\n",
    "    X.append(X2)\n",
    "    y.append(y1)\n",
    "    y.append(y2)\n",
    "    camera_view.append(np.zeros(len(X1)))\n",
    "    camera_view.append(np.ones(len(X2)))\n",
    "    print cls\n",
    "    \n",
    "X = np.vstack(X).astype(np.float32)\n",
    "y=np.hstack(y)\n",
    "camera_view=np.hstack(camera_view)\n",
    "\n",
    "#right now, y is a list of strings, so convert to numbers based on alphanumeric order\n",
    "CLASSES=np.sort(os.listdir('/home/kevin/Documents/ARC/Training items/'))\n",
    "LABELS = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "y=np.array([LABELS[i] for i in y]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for the second ARC rotation dataset\n",
    "directory='/home/kevin/Documents/ARC/ARC2017_rotation2/'\n",
    "imlist_by_group=list() #list of stacks of images, where each stack is for one object at one view\n",
    "\n",
    "projection_images=list() #there are 80 of these; projection of all images from a single rotation per camera\n",
    "y=list() #labels for groups (80)\n",
    "for subdir in os.walk(directory): #first get the folders, which contain different classes of images\n",
    "    dir_=subdir[0]\n",
    "    #get the class label\n",
    "    cls=dir_.partition('rotation2/')[-1]\n",
    "    if not cls or 'point_cloud' in cls: #if it's empty (the root directory); point cloud folder is empty\n",
    "        continue\n",
    "    aligned=list() #rgb with depth mask\n",
    "    aligned_numbers=list()\n",
    "    rgb=list()\n",
    "    rgb_numbers=list()\n",
    "    for im in os.listdir(dir_):\n",
    "        if 'point_cloud' in im:\n",
    "            continue\n",
    "        number=int(im.partition('image_')[-1][:-4]) #extract number from name, e.g. image_6058.npy --> 6058\n",
    "        if 'aligned' in im:\n",
    "            aligned.append((number,np.load(dir_+'/'+im)))\n",
    "            aligned_numbers.append(number)\n",
    "        else:\n",
    "            rgb.append((number,np.load(dir_+'/'+im))) #twice as many images, because aligned and non aligned\n",
    "            rgb_numbers.append(number)\n",
    "    aligned=sorted(aligned)\n",
    "    aligned_numbers=sorted(aligned_numbers)\n",
    "    rgb=sorted(rgb)\n",
    "    rgb_numbers=sorted(rgb_numbers)\n",
    "    \n",
    "    #separate rgb into the two camera views:\n",
    "    view0=[i[1] for i in rgb if i[0] in aligned_numbers]\n",
    "    view1=[i[1] for i in rgb if i[0] not in aligned_numbers]\n",
    "    \n",
    "    if not view0 or not view1:\n",
    "        print 'empty directory: '+dir_\n",
    "        continue\n",
    "    \n",
    "    X0 = np.stack(view0).astype(np.float32)\n",
    "    X0proj=np.round(np.mean(X0,0))\n",
    "    #plt.imshow(-X0proj)\n",
    "    #plt.show()\n",
    "    \n",
    "    X1 = np.stack(view1).astype(np.float32)\n",
    "    X1proj=np.round(np.mean(X1,0))\n",
    "    #plt.imshow(-X1proj)\n",
    "    #plt.show()\n",
    "    \n",
    "    #projection_images.append(X0proj)\n",
    "    #projection_images.append(X1proj)\n",
    "    \n",
    "    imlist_by_group.append(X0)\n",
    "    imlist_by_group.append(X1)\n",
    "    y.append(cls)\n",
    "    y.append(cls)\n",
    "    print dir_\n",
    "#projection_images=np.stack(projection_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# #save in matlab format for manual segmentation\n",
    "# import scipy.io\n",
    "# scipy.io.savemat('ARC2017_rotation2_projection_images.mat',{'projection_images':projection_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#input is image, 3,224,224 and a class number, output is same image with added background object/noise\n",
    "def addBackgroundObject(image, classnum):\n",
    "    #swap axes\n",
    "    image_swap = np.swapaxes(image, 0,1)\n",
    "    image_swap = np.swapaxes(image_swap, 1,2)\n",
    "\n",
    "    #get a random class\n",
    "    rand_class = [x for x in range(40) if x!=classnum and x!=12] #fiskar scissors missign\n",
    "    random.shuffle(rand_class)\n",
    "    rand_class = rand_class[0]\n",
    "    \n",
    "    #try to load in an image from that random class\n",
    "    try:\n",
    "        rand_imgs = np.load('/home/kevin/Documents/ARC/cropped_rotation_fromBK/cropped_images' + str(rand_class) + '.npy')\n",
    "    except:\n",
    "        print(\"Unable to load in random image for class {}. Returning\".format(rand_class))\n",
    "        return image\n",
    "    \n",
    "    rand_img = [x for x in range(len(rand_imgs))]\n",
    "    random.shuffle(rand_img)\n",
    "    rand_img = rand_imgs[rand_img[0]]\n",
    "    \n",
    "    #create a new image the same size as the old one\n",
    "    result = np.zeros((1024,1024,3)).astype('uint8')\n",
    "    #convert old image to bw\n",
    "    bw_img = cv2.cvtColor(np.swapaxes(image,0,2),cv2.COLOR_BGR2GRAY)\n",
    "    #find the border pts\n",
    "    _,borderpts,_ = cv2.findContours(bw_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #randomly rotate the bg image\n",
    "    rand_img = scipy.misc.imrotate(rand_img, random.randint(0,360))\n",
    "    \n",
    "    #random border pt\n",
    "    rand_border_pt = random.randint(0,len(borderpts[0])-1)\n",
    "    #stored as y,x\n",
    "    rand_border_pt = borderpts[0][rand_border_pt][0] \n",
    "    \n",
    "\n",
    "    w = rand_img.shape[1]\n",
    "    h = rand_img.shape[0]\n",
    "    centerX = rand_img.shape[1]//2\n",
    "    centerY = rand_img.shape[0]//2\n",
    "    \n",
    "    t = centerY-h//2\n",
    "    b = centerY+h//2\n",
    "    l = centerX-w//2\n",
    "    r = centerX+w//2\n",
    "\n",
    "\n",
    "    #find how much we should use of the bg image\n",
    "    bg_right = rand_border_pt[1] + w//2\n",
    "    bg_left = rand_border_pt[1] - w//2\n",
    "    bg_top = rand_border_pt[0] - h//2\n",
    "    bg_bot = rand_border_pt[0] + h//2\n",
    "    \n",
    "    #order \n",
    "    if bg_right < bg_left:\n",
    "        bg_right, bg_left = bg_left, bg_right\n",
    "\n",
    "    if bg_bot < bg_top:\n",
    "        bg_top, bg_bot = bg_bot, bg_top\n",
    "\n",
    "    #paste the random image in first at a random boundary pt\n",
    "    result[400+bg_top:400+bg_bot, 400+bg_left:400+bg_right,:] = rand_img[t:b, l:r, :]\n",
    "    \n",
    "    result[400:624, 400:624, 0] = np.where(image_swap[:,:, 0]!= 0, image_swap[:, :, 0], result[400:624, 400:624, 0])\n",
    "    result[400:624, 400:624, 1] = np.where(image_swap[:,:, 1]!= 0, image_swap[:, :, 1], result[400:624, 400:624, 1])\n",
    "    result[400:624, 400:624, 2] = np.where(image_swap[:,:, 2]!= 0, image_swap[:, :, 2], result[400:624, 400:624, 2])\n",
    "    \n",
    "    res = result[400:624, 400:624]\n",
    "\n",
    "    #swap axes back\n",
    "    res = np.swapaxes(res, 1, 2)\n",
    "    res = np.swapaxes(res, 0, 1)\n",
    "\n",
    "    return res\n",
    "def get_segmented_images(imlist,box_coords):\n",
    "    #imlist is a list of stacks of images, by object and view\n",
    "    #box_coords is the corresponding coordinates to segment out the objects\n",
    "    \n",
    "    imlist_segmented=list()\n",
    "    for stack,coords in zip(imlist,box_coords):\n",
    "        (y,x,l,w)=np.round(coords).astype(np.int32)\n",
    "        imlist_segmented.append(stack[:,x:x+w,y:y+l,:])\n",
    "    return imlist_segmented\n",
    "\n",
    "def generate_augmented_dataset(imlist,labels,upscale_factor=2,smallest_dim=80,max_translate=40,\n",
    "                               brightness_scale_range=[.4,1.7]): \n",
    "    #imlist is the output of get_segmented_images; i.e., it is a list of stacks for each object for both views\n",
    "    #this function detects the size and accordingly (de)magnifies the image, translates it, and rotates it\n",
    "    \n",
    "    #the output image size is 224x224 to match VGG net\n",
    "    #each raw segmented image will be resized from a range such that the largest dimension will be at most 224\n",
    "    #on the other extreme,the largest dimension will be no smaller than smallest_dim in pixels\n",
    "    #upscale_factor: how many replicates of each raw image to include (with random transformations)\n",
    "    #images will also be randomly rotated, color dithered, and randomly translated in a small region near the center\n",
    "    #max_translate is the maximum distance in pixels to decenter the image in one direction (plus or minus)\n",
    "    #brightness scale range specifies the max and min possible multiplicative factor of the L channel in \n",
    "    #HSL \n",
    "    #random crops are generated by generating a random box size with same aspect ratio as the original image\n",
    "    #but side lengths are scaled between .5 and 1.0 (to guarantee that no more than half othe image is occluded)\n",
    "    \n",
    "    X=list()\n",
    "    y=list()\n",
    "    for stack,coords,y_ in zip(imlist,box_coords,labels):\n",
    "        h,w=stack.shape[1:3] #dimensions of the segmented image\n",
    "        #X_=list()\n",
    "        for im in stack: #all images in a stack share the same bounding box\n",
    "            #random crop:\n",
    "            rawim=np.copy(im)\n",
    "            h,w,_=rawim.shape\n",
    "            h_center=h/2\n",
    "            w_center=w/2\n",
    "            \n",
    "            h_scale=np.random.rand(1)*.5+.5\n",
    "            w_scale=np.random.rand(1)*.5+.5\n",
    "            h_new=int(h*h_scale) #side lengths of the box to sample from the original image\n",
    "            w_new=int(w*w_scale)\n",
    "            \n",
    "            mask=np.zeros((h,w,1))\n",
    "            \n",
    "            #pick random numbers for translating the box crop \n",
    "            h_trans=int((np.random.rand(1)-.5)*(h-h_new))\n",
    "            w_trans=int((np.random.rand(1)-.5)*(w-w_new))\n",
    "            h_center+=h_trans\n",
    "            w_center+=w_trans\n",
    "            mask[h_center-h_new/2:h_center+h_new/2,w_center-w_new/2:w_center+w_new/2,0]=1.\n",
    "            rawim*=mask\n",
    "\n",
    "            #rotate image randomly:\n",
    "            #for opencv, the image is the same dimensions, so cropping occurs after rotation\n",
    "            randangle=np.random.rand(1)[0]*360\n",
    "            #M = cv2.getRotationMatrix2D((w/2,h/2),int(randangle),1)\n",
    "            #rawim = cv2.warpAffine(rawim,M,(w,h))\n",
    "            rawim=rotate(rawim,randangle,order=1) #scipy.ndimage.interpolation; this version doesn't crop\n",
    "            h,w,_=rawim.shape #new shape\n",
    "            \n",
    "            #rescale image\n",
    "            pix_rescale=np.random.rand(1)[0]*(224-smallest_dim)+smallest_dim #number of pixels to rescale to\n",
    "            newim=np.zeros((224,224,3))\n",
    "            if h>w:\n",
    "                dim1=pix_rescale.astype(np.int32)\n",
    "                dim2=(pix_rescale*w/h).astype(np.int32)\n",
    "            else:\n",
    "                dim1=(pix_rescale*h/w).astype(np.int32)\n",
    "                dim2=pix_rescale.astype(np.int32)\n",
    "            \n",
    "            #generate random translation:\n",
    "            dx,dy=np.random.rand((2))\n",
    "            dx=int((dx-.5)*2*max_translate)\n",
    "            dy=int((dy-.5)*2*max_translate)\n",
    "            \n",
    "            #create new image\n",
    "            rawim = skimage.transform.resize(rawim, (dim1,dim2), preserve_range=True)\n",
    "            #safeguard against translating out of the field of view:\n",
    "            lowx=np.maximum(112-dim1/2+dx,0)\n",
    "            highx=np.minimum(112+(dim1-dim1/2+dx),224)\n",
    "            lowy=np.maximum(112-dim2/2+dy,0)\n",
    "            highy=np.minimum(112+(dim2-dim2/2)+dy,224)\n",
    "            rawim=rawim[:highx-lowx,:highy-lowy]\n",
    "            newim[lowx:highx,\n",
    "                  lowy:highy]=rawim\n",
    "            \n",
    "            #random brightness scaling (note; if using opencv, have to convert to 8-bit):\n",
    "            rand_scale=np.random.rand(1)*(brightness_scale_range[1]-brightness_scale_range[0])+brightness_scale_range[0]\n",
    "            im2=cv2.cvtColor(newim.astype(np.uint8),cv2.COLOR_RGB2HLS)\n",
    "            im2[:,:,1]=np.maximum(np.minimum(im2[:,:,1]*rand_scale,255),0) #squeeze between 0 and 255\n",
    "            newim=cv2.cvtColor(im2,cv2.COLOR_HLS2RGB)\n",
    "            \n",
    "            #process the formatting of the image:\n",
    "            # Shuffle axes to c01\n",
    "            newim = np.swapaxes(np.swapaxes(newim, 1, 2), 0, 1)\n",
    "            \n",
    "            #ADD RANDOM BACKGROUND (from brenton); note that the background and foreground don't get same lighting\n",
    "            #newim=addBackgroundObject(newim,LABELS[y_])\n",
    "            \n",
    "            # Convert to BGR\n",
    "            newim = newim[::-1, :, :]\n",
    "            \n",
    "            X.append(newim[np.newaxis])\n",
    "            y.append(y_)\n",
    "        print y_ #print current progress\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import from matlab\n",
    "box_coords=np.round(\n",
    "    scipy.io.loadmat(\n",
    "        'ARC2017_rotation2_projection_SEGMENTATION.mat')['box_coords']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get labels and numbering\n",
    "CLASSES=np.sort(os.listdir('/home/kevin/Documents/ARC/Training items/'))\n",
    "LABELS = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "\n",
    "segmented=get_segmented_images(imlist_by_group,box_coords)\n",
    "X,y=generate_augmented_dataset(segmented,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(segmented[29][0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(30):\n",
    "    plt.imshow(deprocess(np.squeeze(X[i])).astype(np.uint8))\n",
    "    print i\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imlist_by_group=None\n",
    "segmented=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack(X).astype(np.float32)\n",
    "y=np.hstack(y)\n",
    "\n",
    "y=np.array([LABELS[i] for i in y]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X.shape\n",
    "#still need to do color diterhing\n",
    "#don't run the above cell if you wanna see some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(deprocess(np.squeeze(X[6007])))#.astype(np.uint8))))\n",
    "plt.show()\n",
    "plt.imshow(deprocess(np.squeeze(X[6007].astype(np.uint8))))\n",
    "#WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split into train, validation and test sets\n",
    "train_ix, test_ix = sklearn.cross_validation.train_test_split(range(len(y)))\n",
    "train_ix, val_ix = sklearn.cross_validation.train_test_split(range(len(train_ix)))\n",
    "\n",
    "X_tr = X[train_ix]\n",
    "y_tr = y[train_ix]\n",
    "\n",
    "X_val = X[val_ix]\n",
    "y_val = y[val_ix]\n",
    "\n",
    "X_te = X[test_ix]\n",
    "y_te = y[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We'll connect our output classifier to the last fully connected layer of the network\n",
    "output_layer = DenseLayer(net['fc7'], num_units=len(CLASSES), nonlinearity=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if loading a finetuned net\n",
    "output_layer=net['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define loss function and metrics, and get an updates dictionary\n",
    "X_sym = T.tensor4()\n",
    "y_sym = T.ivector()\n",
    "\n",
    "prediction = lasagne.layers.get_output(output_layer, X_sym)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, y_sym)\n",
    "loss = loss.mean()\n",
    "\n",
    "acc = T.mean(T.eq(T.argmax(prediction, axis=1), y_sym),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compile functions for training, validation and prediction\n",
    "train_fn = theano.function([X_sym, y_sym], loss, updates=updates)\n",
    "val_fn = theano.function([X_sym, y_sym], [loss, acc])\n",
    "pred_fn = theano.function([X_sym], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generator splitting an iterable into chunks of maximum length N\n",
    "def batches(iterable, N):\n",
    "    chunk = []\n",
    "    for item in iterable:\n",
    "        chunk.append(item)\n",
    "        if len(chunk) == N:\n",
    "            yield chunk\n",
    "            chunk = []\n",
    "    if chunk:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need a fairly small batch size to fit a large network like this in GPU memory\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_batch():\n",
    "    ix = range(len(y_tr))\n",
    "    np.random.shuffle(ix)\n",
    "    ix = ix[:BATCH_SIZE]\n",
    "    return train_fn(X_tr[ix], y_tr[ix])\n",
    "\n",
    "def val_batch():\n",
    "    ix = range(len(y_val))\n",
    "    np.random.shuffle(ix)\n",
    "    ix = ix[:BATCH_SIZE]\n",
    "    return val_fn(X_val[ix], y_val[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "for epoch in range(25):\n",
    "    start=time()\n",
    "    for batch in range(25):\n",
    "        loss = train_batch()\n",
    "\n",
    "    ix = range(len(y_val))\n",
    "    np.random.shuffle(ix)\n",
    "\n",
    "    loss_tot = 0.\n",
    "    acc_tot = 0.\n",
    "    for chunk in batches(ix, BATCH_SIZE):\n",
    "        loss, acc = val_fn(X_val[chunk], y_val[chunk])\n",
    "        loss_tot += loss * len(chunk)\n",
    "        acc_tot += acc * len(chunk)\n",
    "\n",
    "    loss_tot /= len(ix)\n",
    "    acc_tot /= len(ix)\n",
    "    print(epoch, loss_tot, acc_tot * 100,time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "d_updated=copy.deepcopy(d)\n",
    "_=d_updated.pop('synset words',None)\n",
    "updated_params=list()\n",
    "for i in params: #get new parameter values\n",
    "    updated_params.append(np.array(i.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d_updated['param values']=updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(d_updated,open(\"vgg_finetuned_ARC2017_rotation_2_augmented_norandombackground.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_validation_set(directory,numimages):\n",
    "    #load a list of segmented images from a specified directory\n",
    "    #numimages is the number of images that were manually segmented\n",
    "    def get_image_segments(im,segment_coords):\n",
    "        #given inputs, returns segmented image \n",
    "        #object coordinates:\n",
    "        xy=np.array(segment_coords)\n",
    "\n",
    "        #isolate the object\n",
    "        mask=np.zeros_like(im)\n",
    "        mask[xy[:,1],xy[:,0]]=1\n",
    "        masked=im*mask\n",
    "\n",
    "        #coordinates of corners of the bounding box (unrotated)\n",
    "        x1,y1=np.min(xy,0)\n",
    "        x2,y2=np.max(xy,0)\n",
    "\n",
    "        segment=masked[y1:y2,x1:x2]\n",
    "        #plt.imshow(segment)\n",
    "        return segment\n",
    "\n",
    "    all_segments=list()\n",
    "    all_labels=list()\n",
    "    for i in xrange(numimages):\n",
    "        #load data for an image\n",
    "        try: #either cam1 or cam2\n",
    "            im=np.load(directory+'/image_cam1_'+str(i)+'.npy')\n",
    "            flag='1' #indicates which cam to load from next\n",
    "        except:\n",
    "            im=np.load(directory+'/image_cam2_'+str(i)+'.npy')\n",
    "            flag='2'\n",
    "        try: #segment vs seg in name\n",
    "            segments=np.load(directory+'/image_cam'+flag+'_'+str(i)+'_seg.npy')\n",
    "        except:\n",
    "            segments=np.load(directory+'/image_cam'+flag+'_'+str(i)+'_segmented.npy')   \n",
    "        labels=np.load(directory+'/image_cam'+flag+'_'+str(i)+'_labels.npy')\n",
    "\n",
    "        for (lab,seg) in zip(labels,segments):\n",
    "            if seg: #if not empty:\n",
    "                all_labels.append(lab)\n",
    "                all_segments.append(get_image_segments(im,seg))\n",
    "            else:\n",
    "                print 'image '+str(i)+' has an empty segmentation!'\n",
    "\n",
    "    return all_segments,all_labels\n",
    "\n",
    "def put_validation_segments_on_black_bkgd(segment):\n",
    "    #create a blanks canvas of size 224by224\n",
    "    #if the segment is too large, resize the largest dimension to 224\n",
    "    #no augmentations (e.g., rotations, translations, etc.)\n",
    "    h,w,_=segment.shape\n",
    "    if h>224:\n",
    "        w=int(w*224./h)\n",
    "        h=224\n",
    "    if w>224:\n",
    "        h=int(h*224./w)\n",
    "        w=224\n",
    "\n",
    "    #create new image\n",
    "    segment = skimage.transform.resize(segment, (h,w), preserve_range=True)\n",
    "    \n",
    "    newim=np.zeros((224,224,3))\n",
    "    newim[112-h/2:112-h/2+h,112-w/2:112-w/2+w]=segment\n",
    "    \n",
    "    #process the formatting of the image:\n",
    "    # Shuffle axes to c01\n",
    "    newim = np.swapaxes(np.swapaxes(newim, 1, 2), 0, 1)\n",
    "\n",
    "    # Convert to BGR\n",
    "    newim = newim[::-1, :, :]\n",
    "    \n",
    "    return newim[np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load validation set\n",
    "directory='/home/kevin/Documents/ARC/Manual segmentation/tote_shelf_top_down/tote_shelf1'\n",
    "(segments1,labels1)=load_validation_set(directory,12)\n",
    "directory='/home/kevin/Documents/ARC/Manual segmentation/tote_shelf_top_down/tote_shelf2'\n",
    "(segments2,labels2)=load_validation_set(directory,64)\n",
    "labels=labels1+labels2\n",
    "segments=segments1+segments2\n",
    "\n",
    "#get labels and numbering\n",
    "X_val=list()\n",
    "for segment in segments:\n",
    "    X_val.append(put_validation_segments_on_black_bkgd(segment))\n",
    "    \n",
    "CLASSES=np.sort(os.listdir('/home/kevin/Documents/ARC/Training items/'))\n",
    "LABELS = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "y_val=np.array([LABELS[i] for i in labels]).astype('int32')\n",
    "X_val = np.vstack(X_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute top-k accuracy\n",
    "matches=list() #list of 0s and 1s to indicate whether there is a top k match\n",
    "preds=list() #list of predictions\n",
    "k=3\n",
    "BATCH_SIZE=32\n",
    "ix = range(len(y_val))\n",
    "for chunk in batches(ix, BATCH_SIZE):\n",
    "    p_y=pred_fn(X_val[chunk]).argsort()[:,-k:][:,::-1]\n",
    "    for i in xrange(len(chunk)):\n",
    "        matches.append(y_val[chunk][i] in p_y[i])\n",
    "        preds.append(p_y[i][0]) #store the top prediction\n",
    "\n",
    "print np.mean(matches) #top-k accuracy\n",
    "print np.mean(np.array(preds)==y_val) #accuracy\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf=confusion_matrix(y_val,preds,labels=range(40))    \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(conf,interpolation='none')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('actual')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot some results from the validation set\n",
    "p_y = pred_fn(X_val[:25]).argmax(-1)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(deprocess(X_val[i]).astype(np.uint8))\n",
    "    true = y_val[i]\n",
    "    pred = p_y[i]\n",
    "    color = 'green' if true == pred else 'red'\n",
    "    plt.text(0, 0, true, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "    plt.text(0, 32, pred, color=color, bbox=dict(facecolor='white', alpha=1))\n",
    "\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im=np.copy(X[0:1]).astype(np.uint8)#.astype(np.float32)\n",
    "im=np.swapaxes(im,2,3)\n",
    "plt.imshow(deprocess(im[0]))\n",
    "best5=pred_fn(im)[0].argsort()[-5:]\n",
    "for i in best5:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ModifiedBackprop(object):\n",
    "\n",
    "    def __init__(self, nonlinearity):\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.ops = {}  # memoizes an OpFromGraph instance per tensor type\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # OpFromGraph is oblique to Theano optimizations, so we need to move\n",
    "        # things to GPU ourselves if needed.\n",
    "        if theano.sandbox.cuda.cuda_enabled:\n",
    "            maybe_to_gpu = theano.sandbox.cuda.as_cuda_ndarray_variable\n",
    "        else:\n",
    "            maybe_to_gpu = lambda x: x\n",
    "        # We move the input to GPU if needed.\n",
    "        x = maybe_to_gpu(x)\n",
    "        # We note the tensor type of the input variable to the nonlinearity\n",
    "        # (mainly dimensionality and dtype); we need to create a fitting Op.\n",
    "        tensor_type = x.type\n",
    "        # If we did not create a suitable Op yet, this is the time to do so.\n",
    "        if tensor_type not in self.ops:\n",
    "            # For the graph, we create an input variable of the correct type:\n",
    "            inp = tensor_type()\n",
    "            # We pass it through the nonlinearity (and move to GPU if needed).\n",
    "            outp = maybe_to_gpu(self.nonlinearity(inp))\n",
    "            # Then we fix the forward expression...\n",
    "            op = theano.OpFromGraph([inp], [outp])\n",
    "            # ...and replace the gradient with our own (defined in a subclass).\n",
    "            op.grad = self.grad\n",
    "            # Finally, we memoize the new Op\n",
    "            self.ops[tensor_type] = op\n",
    "        # And apply the memoized Op to the input we got.\n",
    "        return self.ops[tensor_type](x)\n",
    "class GuidedBackprop(ModifiedBackprop):\n",
    "    def grad(self, inputs, out_grads):\n",
    "        (inp,) = inputs\n",
    "        (grd,) = out_grads\n",
    "        dtype = inp.dtype\n",
    "        return (grd * (inp > 0).astype(dtype) * (grd > 0).astype(dtype),)\n",
    "    \n",
    "def compile_saliency_function():\n",
    "    \"\"\"\n",
    "    Compiles a function to compute the saliency maps and predicted classes\n",
    "    for a given minibatch of input images.\n",
    "    \"\"\"\n",
    "    inp = net['input'].input_var\n",
    "    outp = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "    max_outp = T.max(outp, axis=1)\n",
    "    saliency = theano.grad(max_outp.sum(), wrt=inp)\n",
    "    max_class = T.argmax(outp, axis=1)\n",
    "    return theano.function([inp], [saliency, max_class])\n",
    "\n",
    "def compile_saliency_function_arbitrary_class():\n",
    "    #the function outputted by this def takes in both an image and a class\n",
    "    class_num_var=T.scalar(dtype='int32')\n",
    "    \n",
    "    inp = net['input'].input_var\n",
    "    outp = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "    outp_class=outp[0,class_num_var]\n",
    "    saliency = theano.grad(outp_class, wrt=inp)\n",
    "    return theano.function([inp,class_num_var], [saliency])\n",
    "\n",
    "def show_images(img_original, saliency, max_class, title):\n",
    "    # get out the first map and class from the mini-batch\n",
    "    saliency = saliency[0]\n",
    "    max_class = max_class[0]\n",
    "    # convert saliency from BGR to RGB, and from c01 to 01c\n",
    "    saliency = saliency[::-1].transpose(1, 2, 0)\n",
    "    # plot the original image and the three saliency map variants\n",
    "    plt.figure(figsize=(10, 10), facecolor='w')\n",
    "    plt.suptitle(\"Class: \" + CLASSES[max_class] + \". Saliency: \" + title)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('input')\n",
    "    plt.imshow(img_original)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('abs. saliency')\n",
    "    plt.imshow(np.abs(saliency).max(axis=-1), cmap='gray')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('pos. saliency')\n",
    "    plt.imshow((np.maximum(0, saliency) / saliency.max()))\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('neg. saliency')\n",
    "    plt.imshow((np.maximum(0, -saliency) / -saliency.min()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "relu = lasagne.nonlinearities.rectify\n",
    "relu_layers = [layer for layer in lasagne.layers.get_all_layers(output_layer)\n",
    "               if getattr(layer, 'nonlinearity', None) is relu]\n",
    "#modded_relu = GuidedBackprop(relu)  # important: only instantiate this once!\n",
    "for layer in relu_layers:\n",
    "    layer.nonlinearity = modded_relu\n",
    "    \n",
    "saliency_fn = compile_saliency_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saliency_fn_var = compile_saliency_function_arbitrary_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i=142\n",
    "im=X_val[i:i+1]\n",
    "class_num=np.array([0]).astype(np.int32)\n",
    "saliency = saliency_fn_var(im,class_num[0])\n",
    "show_images(deprocess(im[0]).astype(np.uint8), saliency[0], class_num, \"guided backprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saliency[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i=142\n",
    "im=X_val[i:i+1]\n",
    "#im=np.roll(im,-50,3)\n",
    "saliency, max_class = saliency_fn(im)\n",
    "show_images(deprocess(im[0]).astype(np.uint8), saliency, max_class, \"guided backprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[0,0])\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
